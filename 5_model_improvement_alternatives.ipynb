{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Model Improvement and Alternatives\n",
    "\n",
    "In this notebook, we will look for different ways to improve the result, including but not limited to:\n",
    "\n",
    "- Changing time interval for forward price changes;\n",
    "- Using different number of hidden layers and hidden dimensions;\n",
    "- Using other regressor algorithms by Sagemaker\n",
    "\n",
    "To make things more convenient, a helper class `SagemakerEstimatorHelper` is provided in `model_helper.py` to shorten codes needed to evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from model_helper import *\n",
    "from data_processing import *\n",
    "from data_reader import *\n",
    "from features_helper import *\n",
    "from plotting_helper import *\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session, role,  = sagemaker.Session(), sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "data_dir, prefix = 'processed_data', 'sagemaker/capstone_capstone'\n",
    "output_path = f's3://{bucket}/{prefix}'\n",
    "original_df = read_all_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different alternatives will be labelled by a tag, and the training result will be stored in the `summary_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', 'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=False)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=1)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_6\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['original'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 1: Using more layers of neurons in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', 'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=False)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=1)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_10_8_6_4\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['more_layers'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | More Layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | More Layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 2: Use fewer number of features (same number of layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=True)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=1)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_6\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['less_features'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | Less Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | Less Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 3: Use more number of features (same number of layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = helper.get_available_features()\n",
    "helper.run_features_list(target_features_list, log=True)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=1)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "summary_dict['more_features'] = {}\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_6\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['more_features'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | More Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | More Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 3: Predicting forward price changes of a different interval (5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', \n",
    "                        'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=False)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=5)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_6\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['5_minutes'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | 5 Minutes Forward Price Changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | 5 Minutes Forward Price Changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 4: Predicting forward price changes of a different interval (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', \n",
    "                        'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=False)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=10)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='neural_network', \n",
    "                                  output_path=output_path, \n",
    "                                  train_entry_point='train.py',\n",
    "                                  predict_entry_point='predict.py',\n",
    "                                  source_dir='source', \n",
    "                                  hyperparameters={'input_dim': len(target_features_list),\n",
    "                                                   'hidden_dim_list': \"8_6\",\n",
    "                                                   'output_dim': 1,\n",
    "                                                   'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['10_minutes'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Neural Network | 10 Minutes Forward Price Changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Neural Network | 10 Minutes Forward Price Changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 5: Predicting forward price changes using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper = FeaturesHelper(original_df)\n",
    "# target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', \n",
    "#                         'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "# helper.run_features_list(target_features_list, log=False)\n",
    "# df = preprocess_data(helper.get_result(bool_dropna=True), input_period=10)\n",
    "\n",
    "# input_df = df.copy()\n",
    "# train_df, test_df = split_train_test_df(input_df)\n",
    "# label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# # Define model\n",
    "# helper = SagemakerEstimatorHelper(target_algorithm='xgboost', \n",
    "#                                   output_path=output_path)\n",
    "# helper.set_hyperparameters(input_hyperparameters={'max_depth': 5,\n",
    "#                                                   'eta': 0.2,\n",
    "#                                                   'gamma': 4,\n",
    "#                                                   'min_child_weight': 6,\n",
    "#                                                   'subsample': 0.8,\n",
    "#                                                   'early_stopping_rounds': 10,\n",
    "#                                                   'num_round': 200})\n",
    "\n",
    "# # Upload data to S3\n",
    "# helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "# helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# # Train and Deploy model\n",
    "# helper.est_fit()\n",
    "# helper.deploy()\n",
    "\n",
    "# # Predict after deployment\n",
    "# train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "# test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "# summary_dict['xgboost'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "\n",
    "# # Delete endpoint\n",
    "# helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "# plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | XGBoost | Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "# plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | XGBoost | Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 6: Predicting forward price changes using LinearLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helper = FeaturesHelper(original_df)\n",
    "target_features_list = ['60m_chg_std', '60m_z_price', '60m_z_volume', '60m_draw_up', '60m_draw_down', '5m_smoothed_volume_chg', \n",
    "                        'log_volume', 'close_to_high', 'close_to_low', 'close_to_open', 'adx', 'macd', 'fso']\n",
    "helper.run_features_list(target_features_list, log=False)\n",
    "df = preprocess_data(helper.get_result(bool_dropna=True), input_period=10)\n",
    "\n",
    "input_df = df.copy()\n",
    "train_df, test_df = split_train_test_df(input_df)\n",
    "label_col, feature_cols = train_df.columns[0], train_df.columns[1:]\n",
    "\n",
    "# Define model\n",
    "helper = SagemakerEstimatorHelper(target_algorithm='linear_learner', \n",
    "                                  output_path=output_path, \n",
    "                                  hyperparameters={'epochs': 100})\n",
    "\n",
    "# Upload data to S3\n",
    "helper.upload_data(train_df, 'train', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "helper.upload_data(test_df, 'test', data_dir=data_dir, prefix=prefix, force_update=True)\n",
    "\n",
    "# Train and Deploy model\n",
    "helper.est_fit()\n",
    "helper.deploy()\n",
    "\n",
    "# Predict after deployment\n",
    "train_preds = helper.predict_in_chunks(train_df[feature_cols])\n",
    "test_preds = helper.predict_in_chunks(test_df[feature_cols])\n",
    "summary_dict['linear_learner'] = evalute_result(train_pred_array=train_preds, train_label_array=train_df[label_col], test_pred_array=test_preds, test_label_array=test_df[label_col])\n",
    "\n",
    "\n",
    "# Delete endpoint\n",
    "helper.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set plotting\n",
    "plot_predictions(predictions_array=train_preds, actuals_array=train_df[label_col], title='Train | Linear Learner | Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set plotting\n",
    "plot_predictions(predictions_array=test_preds, actuals_array=test_df[label_col], title='Test | Linear Learner | Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap-up: Save summary to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('summary_dict.json', 'w') as f:\n",
    "    json.dump(summary_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
